{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claude & AWS Bedrock API Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "# import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bedrock Runtime Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some models are not available on all regions. To solve the problem of which model is present in which region, we have inference profiles.\n",
    "\n",
    "## Inference Profile\n",
    "Automatically routes request to other regions where a specific model is hosted. If it is not in us-east-2 and present in us-west-2, then it will automatically request for it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the inference profile ID for on-demand access\n",
    "model_id = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"text\": \"What is 1+1?\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.converse(\n",
    "    modelId = model_id,\n",
    "    messages = [user_message]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '67f0b361-88d3-4766-84ac-efab63819c42',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 21 Aug 2025 16:51:11 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '298',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '67f0b361-88d3-4766-84ac-efab63819c42'},\n",
       "  'RetryAttempts': 0},\n",
       " 'output': {'message': {'role': 'assistant',\n",
       "   'content': [{'text': '1+1 = 2'}]}},\n",
       " 'stopReason': 'end_turn',\n",
       " 'usage': {'inputTokens': 14,\n",
       "  'outputTokens': 11,\n",
       "  'totalTokens': 25,\n",
       "  'cacheReadInputTokens': 0,\n",
       "  'cacheWriteInputTokens': 0},\n",
       " 'metrics': {'latencyMs': 898}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 = 2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': [{'text': '1+1 = 2'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do the following, it would be sent off as a new message without the previous context\n",
    "\n",
    "```python\n",
    "response = client.converse(\n",
    "    modelId = model_id,\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\n",
    "                \"text\": \"And 3 more?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversations\n",
    "\n",
    "### Helper Functions to Maintain Context of Prev Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_message(messages: list[dict], text: str) -> None:\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assistant_message(messages: list[dict], text: str) -> None:\n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ]\n",
    "    }\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "def chat(messages: list[dict]) -> str:\n",
    "    response = client.converse(\n",
    "        modelId = model_id,\n",
    "        messages = messages\n",
    "    )\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'text': 'What is 1+1?'}]}]\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize a list of messages\n",
    "messages = []\n",
    "\n",
    "# 2. Add in the initial user message\n",
    "add_user_message(messages, \"What is 1+1?\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1 = 2.\n"
     ]
    }
   ],
   "source": [
    "# 3. Pass the list of messages into the chat to get an answer\n",
    "answer = chat(messages)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'text': 'What is 1+1?'}]}, {'role': 'assistant', 'content': [{'text': '1+1 = 2.'}]}]\n"
     ]
    }
   ],
   "source": [
    "# 4. Take the answer & add it as an assistant message in our list\n",
    "add_assistant_message(messages, answer)\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'text': 'What is 1+1?'}]}, {'role': 'assistant', 'content': [{'text': '1+1 = 2.'}]}, {'role': 'user', 'content': [{'text': \"And what's 3 more?\"}]}]\n"
     ]
    }
   ],
   "source": [
    "# 5. Add the user's follow up question\n",
    "add_user_message(messages, \"And what's 3 more?\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you add 3 more to 2, the result would be 5.\n",
      "\n",
      "So, 2 + 3 = 5.\n"
     ]
    }
   ],
   "source": [
    "# 6. Call chat again with the list of messages to get the final answer\n",
    "answer = chat(messages)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Chatbot Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "You >> In one word what's the capital of Australia?\n",
      "AI >> Canberra.\n",
      "---------------xxx---------------\n",
      "---------------------------------\n",
      "You >> Canada?\n",
      "AI >> Ottawa.\n",
      "---------------xxx---------------\n",
      "---------------------------------\n",
      "You >> India?\n",
      "AI >> Delhi.\n",
      "---------------xxx---------------\n",
      "Goodbye! Exiting chat...\n"
     ]
    }
   ],
   "source": [
    "# initial list of messages\n",
    "messages = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You >> \")\n",
    "\n",
    "    # Check for exit commands\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye', 'q']:\n",
    "        print(\"Goodbye! Exiting chat...\")\n",
    "        break\n",
    "\n",
    "    # In VSCode print the input too:\n",
    "    print(\"---------------------------------\")\n",
    "    print(f\"You >> {user_input}\")\n",
    "\n",
    "    # Add user's input to list of messages\n",
    "    add_user_message(messages, user_input)\n",
    "\n",
    "    # Send list of messages to Claude on Bedrock\n",
    "    answer = chat(messages)\n",
    "\n",
    "    # Add generated text to list of messages\n",
    "    add_assistant_message(messages, answer)\n",
    "\n",
    "    # Print the generated text for the user to see\n",
    "    print(\"AI >> \"+answer)\n",
    "    print(\"---------------xxx---------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
